{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import layers, models, callbacks\n"
      ],
      "metadata": {
        "id": "reVLhsnA2KJ9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "import random\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "U_h-f0LGTJYz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect and initialize TPU\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    print('TPU not found. Using default strategy.')\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"Number of devices: \", strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbE9Qq_gTSIV",
        "outputId": "025e840f-37ce-44a7-d4fd-7644e48a4351"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU not found. Using default strategy.\n",
            "Number of devices:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDEQrj0U74UZ",
        "outputId": "b0a8febb-42e8-4456-b7d8-2a8e90ec2911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/sahilchambyal/solana-price-usd?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140M/140M [00:01<00:00, 87.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/sahilchambyal/solana-price-usd/versions/1/SOLUSD_1s_01NOV2024_to15NOV2024.csv\n",
            "/root/.cache/kagglehub/datasets/sahilchambyal/solana-price-usd/versions/1/SOLUSD_1s_05NOV2024_to15NOV2024.csv\n",
            "/root/.cache/kagglehub/datasets/sahilchambyal/solana-price-usd/versions/1/SOLUSD_1min_20AUG2020_to15NOV2024.csv\n"
          ]
        }
      ],
      "source": [
        "data_path = kagglehub.dataset_download('sahilchambyal/solana-price-usd')\n",
        "\n",
        "# List the files inside the downloaded data directory\n",
        "for dirname, _, filenames in os.walk(data_path):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6_suMB0TqPYq"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(data_path + '/SOLUSD_1min_20AUG2020_to15NOV2024.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "Yitx8frwqT5O",
        "outputId": "0e772cfe-d870-4c8a-e7e2-f6eba56d06ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenTime               0\n",
              "Open                   0\n",
              "High                   0\n",
              "Low                    0\n",
              "Close                  0\n",
              "Volume                 0\n",
              "CloseTime              0\n",
              "QuoteAssetVolume       0\n",
              "NumberOfTrades         0\n",
              "TakerBuyBaseVolume     0\n",
              "TakerBuyQuoteVolume    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>OpenTime</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Open</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Low</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Close</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volume</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CloseTime</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuoteAssetVolume</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumberOfTrades</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TakerBuyBaseVolume</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TakerBuyQuoteVolume</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Convert OpenTime and CloseTime to datetime if necessary\n",
        "df['OpenTime'] = pd.to_datetime(df['OpenTime'], unit='ms')\n",
        "df['CloseTime'] = pd.to_datetime(df['CloseTime'], unit='ms')\n",
        "\n",
        "# Sort by OpenTime to ensure chronological order\n",
        "df.sort_values('OpenTime', inplace=True)\n",
        "\n",
        "# Reset index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(['Ignore'], axis=1, inplace=True)\n",
        "\n",
        "# Handle missing values if any\n",
        "df.isnull().sum()\n",
        "# Assuming no missing values; if present, handle accordingly\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YKcY1_UETZIV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fEJMzX-dqYIt"
      },
      "outputs": [],
      "source": [
        "# Add lagged 'Close' prices as features\n",
        "df['Close_lag1'] = df['Close'].shift(1)\n",
        "df['Close_lag2'] = df['Close'].shift(2)\n",
        "df['Close_lag3'] = df['Close'].shift(3)\n",
        "\n",
        "# Drop rows with NaN values resulting from lagging\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Define input features and target\n",
        "features_columns = ['Open', 'High', 'Low', 'Close', 'Volume',\n",
        "                    'QuoteAssetVolume', 'NumberOfTrades',\n",
        "                    'TakerBuyBaseVolume', 'TakerBuyQuoteVolume',\n",
        "                    'Close_lag1', 'Close_lag2', 'Close_lag3']\n",
        "target_column = 'Close'\n",
        "\n",
        "# Initialize scalers\n",
        "feature_scaler = MinMaxScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "# Scale features and target\n",
        "scaled_features = feature_scaler.fit_transform(df[features_columns])\n",
        "scaled_target = target_scaler.fit_transform(df[[target_column]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xLxlogWqZLO"
      },
      "outputs": [],
      "source": [
        "# Define sequence lengths\n",
        "INPUT_SEQ_LEN = 60     # Number of past time steps to use as input\n",
        "OUTPUT_SEQ_LEN = 1440  # Number of future time steps to predict (next day)\n",
        "\n",
        "# Function to create input-output sequences for multi-step forecasting\n",
        "def create_multi_step_sequences(features, target, input_seq_len, output_seq_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(features) - input_seq_len - output_seq_len + 1):\n",
        "        X.append(features[i:i + input_seq_len])\n",
        "        y.append(target[i + input_seq_len:i + input_seq_len + output_seq_len])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Create sequences\n",
        "X, y = create_multi_step_sequences(scaled_features, scaled_target, INPUT_SEQ_LEN, OUTPUT_SEQ_LEN)\n",
        "\n",
        "print(\"X shape:\", X.shape)  # Expected shape: (num_samples, INPUT_SEQ_LEN, num_features)\n",
        "print(\"y shape:\", y.shape)  # Expected shape: (num_samples, OUTPUT_SEQ_LEN, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLJnnUZJqbl5"
      },
      "outputs": [],
      "source": [
        "# Train-validation-test split\n",
        "train_size = int(len(X) * 0.8)\n",
        "val_size = int(len(X) * 0.9)\n",
        "\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_val, y_val = X[train_size:val_size], y[train_size:val_size]\n",
        "X_test, y_test = X[val_size:], y[val_size:]\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDOarX0Hqgxg"
      },
      "outputs": [],
      "source": [
        "# Define the encoder-decoder model for multi-step forecasting\n",
        "with strategy.scope():\n",
        "    # Encoder\n",
        "    encoder_inputs = layers.Input(shape=(INPUT_SEQ_LEN, X.shape[2]))\n",
        "    encoder_lstm = layers.LSTM(128, return_state=True)\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = layers.RepeatVector(OUTPUT_SEQ_LEN)(encoder_outputs)\n",
        "    decoder_lstm = layers.LSTM(128, return_sequences=True)\n",
        "    decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_outputs = layers.TimeDistributed(layers.Dense(1))(decoder_outputs)\n",
        "\n",
        "    # Define the model\n",
        "    model = models.Model(encoder_inputs, decoder_outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "    # Display model summary\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "# Define callbacks\n",
        "early_stop = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_checkpoint = callbacks.ModelCheckpoint(\n",
        "    '/kaggle/working/best_model.weights.h5',\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    save_weights_only=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=256,  # Adjust based on memory constraints\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stop, model_checkpoint],\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvnsauMnriYq"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "model.load_weights('/kaggle/working/best_model.weights.h5')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test MSE: {test_loss}, Test MAE: {test_mae}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux2W06wgrmhc"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Reshape predictions and actual values for inverse transformation\n",
        "predictions_reshaped = predictions.reshape(-1, 1)\n",
        "y_test_reshaped = y_test.reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions and actual values\n",
        "predictions_inverse = target_scaler.inverse_transform(predictions_reshaped)\n",
        "y_test_inverse = target_scaler.inverse_transform(y_test_reshaped)\n",
        "\n",
        "# Reshape back to original multi-step sequences\n",
        "predictions_inverse = predictions_inverse.reshape(predictions.shape)\n",
        "y_test_inverse = y_test_inverse.reshape(y_test.shape)\n",
        "\n",
        "# Plotting the results for the first sample in the test set\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(y_test_inverse[0], label='Actual Close Price')\n",
        "plt.plot(predictions_inverse[0], label='Predicted Close Price')\n",
        "plt.title('LSTM Model Predictions vs Actual (Next Day Close Prices)')\n",
        "plt.xlabel('Time (minutes)')\n",
        "plt.ylabel('Close Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Calculate additional evaluation metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Flatten the arrays for metric calculation\n",
        "y_true_flat = y_test_inverse.flatten()\n",
        "y_pred_flat = predictions_inverse.flatten()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred_flat))\n",
        "r2 = r2_score(y_true_flat, y_pred_flat)\n",
        "print(f'Test RMSE: {rmse}, R² Score: {r2}')"
      ],
      "metadata": {
        "id": "QDEzleqNUtIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}